{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cem in /Users/devkalavadiya/opt/anaconda3/lib/python3.9/site-packages (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /Users/devkalavadiya/opt/anaconda3/lib/python3.9/site-packages (from cem) (1.26.2)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.0 in /Users/devkalavadiya/opt/anaconda3/lib/python3.9/site-packages (from cem) (2.1.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/devkalavadiya/opt/anaconda3/lib/python3.9/site-packages (from pandas<3.0.0,>=2.1.0->cem) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/devkalavadiya/opt/anaconda3/lib/python3.9/site-packages (from pandas<3.0.0,>=2.1.0->cem) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/devkalavadiya/opt/anaconda3/lib/python3.9/site-packages (from pandas<3.0.0,>=2.1.0->cem) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/devkalavadiya/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.0->cem) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install cem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>duration</td>\n",
       "      <td>0.214029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>audience_score</td>\n",
       "      <td>0.175617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tomatometer</td>\n",
       "      <td>0.162220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>weighted_score</td>\n",
       "      <td>0.154320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>year</td>\n",
       "      <td>0.146937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Importance\n",
       "3        duration    0.214029\n",
       "1  audience_score    0.175617\n",
       "0     tomatometer    0.162220\n",
       "2  weighted_score    0.154320\n",
       "4            year    0.146937"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Function to convert duration from '1h 32m' to minutes\n",
    "def convert_duration_improved(duration):\n",
    "    if not isinstance(duration, str):\n",
    "        return np.nan  # Return NaN for non-string values\n",
    "    hours = 0\n",
    "    minutes = 0\n",
    "    parts = duration.split(' ')\n",
    "    for part in parts:\n",
    "        if 'h' in part:\n",
    "            try:\n",
    "                hours = int(part.replace('h', ''))\n",
    "            except ValueError:\n",
    "                hours = 0\n",
    "        elif 'm' in part:\n",
    "            try:\n",
    "                minutes = int(part.replace('m', ''))\n",
    "            except ValueError:\n",
    "                minutes = 0\n",
    "    return hours * 60 + minutes\n",
    "\n",
    "# Read the data\n",
    "file_path = 'Merged_diversity_movies.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Preprocessing\n",
    "df['duration'] = df['duration'].apply(convert_duration_improved)\n",
    "scaler = MinMaxScaler()\n",
    "numerical_columns = ['tomatometer', 'audience_score', 'weighted_score', 'duration', 'year']\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "df['genres'] = df['genres'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(', '))\n",
    "df_exploded = df.explode('genres')\n",
    "df_exploded = pd.get_dummies(df_exploded, columns=['genres', 'rating'])\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Feature selection and splitting data\n",
    "features = df_exploded.drop(columns=['name', 'actors', 'directors', 'Movie', 'Production Budget', 'Domestic Gross', 'WorldwideGross', 'Release Date', 'diversity_score', 'index'])\n",
    "target = df_exploded['diversity_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Displaying feature importance\n",
    "feature_importance = model.feature_importances_\n",
    "importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': feature_importance}).sort_values(by='Importance', ascending=False)\n",
    "importance_df.head()  # Display the top 5 important features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['genres_Action', 'genres_Adventure', 'genres_Animation', 'genres_Biography', 'genres_Comedy', 'genres_Crime', 'genres_Documentary', 'genres_Drama', 'genres_Fantasy', 'genres_History', 'genres_Holiday', 'genres_Horror', 'genres_Kids & Family', 'genres_LGBTQ+', 'genres_Music', 'genres_Musical', 'genres_Mystery & Thriller', 'genres_Romance', 'genres_Sci-Fi', 'genres_War', 'genres_Western', 'rating_G', 'rating_NC-17', 'rating_PG', 'rating_PG-13', 'rating_R', 'rating_TVG', 'rating_TVMA', 'Release Date', 'Domestic Gross', 'Production Budget']\n",
      "Formula:\n",
      "isDiverse ~ name+tomatometer+audience_score+weighted_score+duration+year+actors+directors+index+Movie+WorldwideGross+diversity_score\n",
      "n majority: 2795\n",
      "n minority: 2657\n",
      "Fitting Models on Balanced Samples: 1\\10"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devkalavadiya/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: SVD did not converge in Linear Least Squares\n",
      "Fitting Models on Balanced Samples: 1\\10"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb Cell 3\u001b[0m line \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W2sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m matcher \u001b[39m=\u001b[39m Matcher(treatment, control, yvar\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39misDiverse\u001b[39m\u001b[39m\"\u001b[39m, exclude\u001b[39m=\u001b[39mlist_of_categorical_vars)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W2sZmlsZQ%3D%3D?line=87'>88</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m20175\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W2sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m matcher\u001b[39m.\u001b[39;49mfit_scores(balance\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, nmodels\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymatch/Matcher.py:109\u001b[0m, in \u001b[0;36mMatcher.fit_scores\u001b[0;34m(self, balance, nmodels)\u001b[0m\n\u001b[1;32m    107\u001b[0m glm \u001b[39m=\u001b[39m GLM(y_samp, X_samp, family\u001b[39m=\u001b[39msm\u001b[39m.\u001b[39mfamilies\u001b[39m.\u001b[39mBinomial())\n\u001b[1;32m    108\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     res \u001b[39m=\u001b[39m glm\u001b[39m.\u001b[39;49mfit()\n\u001b[1;32m    110\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_accuracy\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scores_to_accuracy(res, X_samp, y_samp))\n\u001b[1;32m    111\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mappend(res)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/genmod/generalized_linear_model.py:1075\u001b[0m, in \u001b[0;36mGLM.fit\u001b[0;34m(self, start_params, maxiter, method, tol, scale, cov_type, cov_kwds, use_t, full_output, disp, max_start_irls, **kwargs)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[39mif\u001b[39;00m cov_type\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39meim\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1074\u001b[0m         cov_type \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnonrobust\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1075\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_irls(start_params\u001b[39m=\u001b[39;49mstart_params, maxiter\u001b[39m=\u001b[39;49mmaxiter,\n\u001b[1;32m   1076\u001b[0m                           tol\u001b[39m=\u001b[39;49mtol, scale\u001b[39m=\u001b[39;49mscale, cov_type\u001b[39m=\u001b[39;49mcov_type,\n\u001b[1;32m   1077\u001b[0m                           cov_kwds\u001b[39m=\u001b[39;49mcov_kwds, use_t\u001b[39m=\u001b[39;49muse_t, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1078\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1079\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optim_hessian \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39moptim_hessian\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/genmod/generalized_linear_model.py:1216\u001b[0m, in \u001b[0;36mGLM._fit_irls\u001b[0;34m(self, start_params, maxiter, tol, scale, cov_type, cov_kwds, use_t, **kwargs)\u001b[0m\n\u001b[1;32m   1211\u001b[0m wlsendog \u001b[39m=\u001b[39m (lin_pred \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfamily\u001b[39m.\u001b[39mlink\u001b[39m.\u001b[39mderiv(mu) \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendog\u001b[39m-\u001b[39mmu)\n\u001b[1;32m   1212\u001b[0m             \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset_exposure)\n\u001b[1;32m   1213\u001b[0m wls_mod \u001b[39m=\u001b[39m reg_tools\u001b[39m.\u001b[39m_MinimalWLS(wlsendog, wlsexog,\n\u001b[1;32m   1214\u001b[0m                                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights, check_endog\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1215\u001b[0m                                 check_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1216\u001b[0m wls_results \u001b[39m=\u001b[39m wls_mod\u001b[39m.\u001b[39;49mfit(method\u001b[39m=\u001b[39;49mwls_method)\n\u001b[1;32m   1217\u001b[0m lin_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexog, wls_results\u001b[39m.\u001b[39mparams)\n\u001b[1;32m   1218\u001b[0m lin_pred \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_offset_exposure\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/statsmodels/regression/_tools.py:101\u001b[0m, in \u001b[0;36m_MinimalWLS.fit\u001b[0;34m(self, method)\u001b[0m\n\u001b[1;32m     99\u001b[0m     params \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39msolve(R, np\u001b[39m.\u001b[39mdot(Q\u001b[39m.\u001b[39mT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwendog))\n\u001b[1;32m    100\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 101\u001b[0m     params, _, _, _ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49mlstsq(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwexog, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwendog,\n\u001b[1;32m    102\u001b[0m                                       rcond\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults(params)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mlstsq\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/linalg/linalg.py:2306\u001b[0m, in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2303\u001b[0m \u001b[39mif\u001b[39;00m n_rhs \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2304\u001b[0m     \u001b[39m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[39;00m\n\u001b[1;32m   2305\u001b[0m     b \u001b[39m=\u001b[39m zeros(b\u001b[39m.\u001b[39mshape[:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m] \u001b[39m+\u001b[39m (m, n_rhs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), dtype\u001b[39m=\u001b[39mb\u001b[39m.\u001b[39mdtype)\n\u001b[0;32m-> 2306\u001b[0m x, resids, rank, s \u001b[39m=\u001b[39m gufunc(a, b, rcond, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[1;32m   2307\u001b[0m \u001b[39mif\u001b[39;00m m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2308\u001b[0m     x[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# !pip install pymatch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pymatch.Matcher import Matcher\n",
    "\n",
    "def convert_duration_improved(duration):\n",
    "    if not isinstance(duration, str):\n",
    "        return np.nan  # Return NaN for non-string values\n",
    "    hours = 0\n",
    "    minutes = 0\n",
    "    parts = duration.split(' ')\n",
    "    for part in parts:\n",
    "        if 'h' in part:\n",
    "            try:\n",
    "                hours = int(part.replace('h', ''))\n",
    "            except ValueError:\n",
    "                hours = 0\n",
    "        elif 'm' in part:\n",
    "            try:\n",
    "                minutes = int(part.replace('m', ''))\n",
    "            except ValueError:\n",
    "                minutes = 0\n",
    "    return hours * 60 + minutes\n",
    "\n",
    "# Read the data\n",
    "file_path = 'Merged_diversity_movies_isDiverse.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "def cleanCurrency(x):\n",
    "    if isinstance(x, str):\n",
    "        return x.replace('$', '').replace(',', '')\n",
    "    return x\n",
    "\n",
    "# Preprocessing\n",
    "df['duration'] = df['duration'].apply(convert_duration_improved)\n",
    "scaler = MinMaxScaler()\n",
    "numerical_columns = ['tomatometer', 'audience_score', 'weighted_score', 'duration', 'year']\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "df['genres'] = df['genres'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(', '))\n",
    "df_exploded = df.explode('genres')\n",
    "df_exploded = pd.get_dummies(df_exploded, columns=['genres', 'rating'])\n",
    "list_of_categorical_vars = ['genres_Action', 'genres_Adventure',\n",
    "       'genres_Animation', 'genres_Biography', 'genres_Comedy', 'genres_Crime',\n",
    "       'genres_Documentary', 'genres_Drama', 'genres_Fantasy',\n",
    "       'genres_History', 'genres_Holiday', 'genres_Horror',\n",
    "       'genres_Kids & Family', 'genres_LGBTQ+', 'genres_Music',\n",
    "       'genres_Musical', 'genres_Mystery & Thriller', 'genres_Romance',\n",
    "       'genres_Sci-Fi', 'genres_War', 'genres_Western', 'rating_G',\n",
    "       'rating_NC-17', 'rating_PG', 'rating_PG-13', 'rating_R', 'rating_TVG',\n",
    "       'rating_TVMA', 'Release Date', 'Domestic Gross', 'Production Budget']\n",
    "# list_of_categorical_vars = [col for col in df_exploded.columns if 'genres_' in col or 'rating_' in col]\n",
    "# \n",
    "print(list_of_categorical_vars)\n",
    "\n",
    "# Feature selection and splitting data\n",
    "features = df_exploded.drop(columns=['name', 'actors', 'directors', 'Movie', 'Production Budget', 'Domestic Gross', 'WorldwideGross', 'Release Date', 'diversity_score', 'index'])\n",
    "target = df_exploded['isDiverse']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Training the model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# # CEM\n",
    "# matcher = Matcher(X_train, X_test, y_train, y_test, list_of_categorical_vars)\n",
    "\n",
    "#isDiverse is binary variable treatment and control\n",
    "treatment = df_exploded[df_exploded['isDiverse'] == 1]\n",
    "control = df_exploded[df_exploded['isDiverse'] == 0]\n",
    "\n",
    "# Remove '$' and ',' before converting to int\n",
    "# treatment['Domestic Gross'] = treatment['Domestic Gross'].replace('[\\$,]', '', regex=True).astype(int)\n",
    "# control['Domestic Gross'] = control['Domestic Gross'].replace('[\\$,]', '', regex=True).astype(int)\n",
    "\n",
    "matcher = Matcher(treatment, control, yvar=\"isDiverse\", exclude=list_of_categorical_vars)\n",
    "np.random.seed(20175)\n",
    "matcher.fit_scores(balance=True, nmodels=10)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/devkalavadiya/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:461: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "/Users/devkalavadiya/opt/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:462: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb Cell 4\u001b[0m line \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m numerical_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mtomatometer\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maudience_score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mweighted_score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df[numerical_columns] \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(df[numerical_columns])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mgenres\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: x\u001b[39m.\u001b[39;49mstrip(\u001b[39m\"\u001b[39;49m\u001b[39m[]\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mreplace(\u001b[39m\"\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m, \u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df_exploded \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mexplode(\u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df_exploded \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(df_exploded, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:4357\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4248\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4249\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4252\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4253\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FrameOrSeriesUnion:\n\u001b[1;32m   4254\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4255\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4256\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4355\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4356\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4357\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1043\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1040\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> 1043\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/apply.py:1098\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1092\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1093\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1095\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1099\u001b[0m             values,\n\u001b[1;32m   1100\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1101\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1102\u001b[0m         )\n\u001b[1;32m   1104\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1105\u001b[0m     \u001b[39m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[1;32m   1106\u001b[0m     \u001b[39m# so extension arrays can be used\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2859\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb Cell 4\u001b[0m line \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m numerical_columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mtomatometer\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39maudience_score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mweighted_score\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39myear\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m df[numerical_columns] \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mfit_transform(df[numerical_columns])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39;49mstrip(\u001b[39m\"\u001b[39m\u001b[39m[]\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m df_exploded \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mexplode(\u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/devkalavadiya/Desktop/CSS/CSS-Final-Project/CEM.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m df_exploded \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mget_dummies(df_exploded, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mgenres\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "from pymatch.Matcher import Matcher\n",
    "\n",
    "# Additional preprocessing as per user's code\n",
    "df['duration'] = df['duration'].apply(convert_duration_improved)\n",
    "scaler = MinMaxScaler()\n",
    "numerical_columns = ['tomatometer', 'audience_score', 'weighted_score', 'duration', 'year']\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "df['genres'] = df['genres'].apply(lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(', '))\n",
    "df_exploded = df.explode('genres')\n",
    "df_exploded = pd.get_dummies(df_exploded, columns=['genres', 'rating'])\n",
    "\n",
    "# Defining the list of categorical variables\n",
    "list_of_categorical_vars = [col for col in df_exploded.columns if 'genres_' in col or 'rating_' in col]\n",
    "\n",
    "# Feature selection and splitting data\n",
    "features = df_exploded.drop(columns=['name', 'actors', 'directors', 'Movie', 'Production Budget', 'Domestic Gross', 'WorldwideGross', 'Release Date', 'diversity_score', 'index'])\n",
    "target = df_exploded['isDiverse']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing the Matcher\n",
    "matcher = Matcher(X_train, X_test, y_train, y_test, list_of_categorical_vars, replace=True)\n",
    "np.random.seed(20170925)\n",
    "matcher.fit_scores(balance=True, nmodels=100)\n",
    "matcher.predict_scores()\n",
    "matcher.evaluate_perf()\n",
    "\n",
    "# Results of the evaluation\n",
    "matcher_performace = matcher.perf_df\n",
    "matcher_performace.head()  # Display the performance of the matcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1161\n",
      "1    1161\n",
      "Name: isDiverse, dtype: int64\n",
      "0.2141836682293353\n"
     ]
    }
   ],
   "source": [
    "file_path = 'Merged_diversity_movies.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# create a isDiverse column with 1 if diversity_score > the median of diversity_score, 0 otherwise\n",
    "df['isDiverse'] = df['diversity_score'].apply(lambda x: 1 if x > df['diversity_score'].median() else 0)\n",
    "\n",
    "# save it to a csv file\n",
    "df.to_csv('Merged_diversity_movies_isDiverse.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
